{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import email\n",
    "from email.parser import Parser\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_decode(payload, encoding='ISO-8859-1'):\n",
    "    try:\n",
    "        return payload.decode(encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        return payload.decode(encoding, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Lowercasing, removing non-alphabetic characters.\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(email_text, label):\n",
    "    # Parse the email\n",
    "    msg = Parser().parsestr(email_text)\n",
    "\n",
    "    # Extract details\n",
    "    from_ = msg['Return-Path'] or msg['From'] or msg['Sender']\n",
    "    subject_ = msg['subject']\n",
    "    date_ = msg['date']\n",
    "    content_type_ = msg.get_content_type()\n",
    "    payload = msg.get_payload()\n",
    "\n",
    "    # Get the email body\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == 'text/plain' or part.get_content_type() == 'text/html':\n",
    "                payload = safe_decode(part.get_payload(decode=True))\n",
    "                break\n",
    "    else:\n",
    "        payload = safe_decode(msg.get_payload(decode=True))\n",
    "\n",
    "    # Parse HTML content to extract text if it's HTML\n",
    "    if 'html' in content_type_:\n",
    "        soup = BeautifulSoup(payload, 'lxml')\n",
    "        text_content = soup.get_text()\n",
    "    else:\n",
    "        text_content = payload\n",
    "    \n",
    "    text_content= preprocess(text_content)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'From': [from_],\n",
    "        'Subject': [subject_],\n",
    "        'Date': [date_],\n",
    "        'Content': [text_content],\n",
    "        'Label': [label]\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(folder_path):\n",
    "    data = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "                content = f.read()\n",
    "                data.append(content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    return pd.DataFrame(data, columns=['email_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  From  \\\n",
      "0                      <update@list.theregister.co.uk>   \n",
      "1    <Online#3.20520.de-C6GhlCa9O-fqvRRR.1.b@newsle...   \n",
      "2    <Online#3.20092.f4-61ydl6cOGxh31RRR.1.b@newsle...   \n",
      "3    <Online#3.19965.2a-726zgP3UI7kTO9RR.1.b@newsle...   \n",
      "4    <bounce-lglinux-2534371@sprocket.lockergnome.com>   \n",
      "..                                                 ...   \n",
      "995                              <fork-admin@xent.com>   \n",
      "996                  <rpm-zzzlist-admin@freshrpms.net>   \n",
      "997                              <fork-admin@xent.com>   \n",
      "998                              <fork-admin@xent.com>   \n",
      "999                     <exmh-users-admin@example.com>   \n",
      "\n",
      "                                               Subject  \\\n",
      "0                      Reg Headlines Wednesday July 17   \n",
      "1          Cordless phones: the other wireless devices   \n",
      "2    Four free e-mailers reviewed, Get the gear you...   \n",
      "3    Get the most out of your games and graphics! (...   \n",
      "4             [Lockergnome Penguin Shell]  Good Hearts   \n",
      "..                                                 ...   \n",
      "995  Re: EBusiness Webforms: cluetrain has left the...   \n",
      "996         Re: use new apt to do null to RH8 upgrade?   \n",
      "997         RE: Selling Wedded Bliss (was Re: Ouch...)   \n",
      "998                                    Re: Rambus, Man   \n",
      "999                                           Re: From   \n",
      "\n",
      "                                      Date  \\\n",
      "0          Wed, 17 Jul 2002 03:00:01 +0100   \n",
      "1    Thu, 18 Jul 2002 17:20:20 -0700 (PDT)   \n",
      "2    Mon, 15 Jul 2002 16:43:30 -0700 (PDT)   \n",
      "3    Fri, 12 Jul 2002 13:36:40 -0700 (PDT)   \n",
      "4          Tue, 16 Jul 2002 12:17:29 -0500   \n",
      "..                                     ...   \n",
      "995        Sat, 28 Sep 2002 23:25:21 +0530   \n",
      "996         Wed, 2 Oct 2002 03:00:39 -0500   \n",
      "997         Sat, 7 Sep 2002 13:52:44 -0400   \n",
      "998  Mon, 26 Aug 2002 20:13:53 -0700 (PDT)   \n",
      "999        Wed, 09 Oct 2002 15:05:00 -0600   \n",
      "\n",
      "                                               Content      Label  aa  aablog  \\\n",
      "0    today s headlines from the register to unsubsc...  hard_spam   0       0   \n",
      "1    cnet cell phone newsletter wireless all cnet t...  hard_spam   0       0   \n",
      "2    software newsletter software mozilla mirc poly...  hard_spam   0       0   \n",
      "3    cnet shopper newsletter sound graphics edition...  hard_spam   0       0   \n",
      "4    lockergnome penguin shell penguinreport career...  hard_spam   0       0   \n",
      "..                                                 ...        ...  ..     ...   \n",
      "995  at am gregory alan bolcer wrote ie and netscap...   easy_ham   0       0   \n",
      "996  on wed oct cest thomas vander stichele thomas ...   easy_ham   0       0   \n",
      "997  cdale is a double chocolate chip macadamia to ...   easy_ham   0       0   \n",
      "998  on mon aug geege wrote summary latest rambus m...   easy_ham   0       0   \n",
      "999  in message g jpgfj fsck intern waldner priv at...   easy_ham   0       0   \n",
      "\n",
      "     aac  aacdwb  aacgv  ...  zwei  zwerg  zwischen  zx  zyxel  zzz  zzzason  \\\n",
      "0      0       0      0  ...     0      0         0   0      0    0        0   \n",
      "1      0       0      0  ...     0      0         0   0      0    0        0   \n",
      "2      0       0      0  ...     0      0         0   0      0    0        0   \n",
      "3      0       0      0  ...     0      0         0   0      0    0        0   \n",
      "4      0       0      0  ...     0      0         0   0      0    0        0   \n",
      "..   ...     ...    ...  ...   ...    ...       ...  ..    ...  ...      ...   \n",
      "995    0       0      0  ...     0      0         0   0      0    0        0   \n",
      "996    0       0      0  ...     0      0         0   0      0    0        0   \n",
      "997    0       0      0  ...     0      0         0   0      0    0        0   \n",
      "998    0       0      0  ...     0      0         0   0      0    0        0   \n",
      "999    0       0      0  ...     0      0         0   0      0    0        0   \n",
      "\n",
      "     zzzickeletto  zzzlist  zzzzteana  \n",
      "0               0        0          0  \n",
      "1               0        0          0  \n",
      "2               0        0          0  \n",
      "3               0        0          0  \n",
      "4               0        0          0  \n",
      "..            ...      ...        ...  \n",
      "995             0        0          0  \n",
      "996             0        0          0  \n",
      "997             0        0          0  \n",
      "998             0        0          0  \n",
      "999             0        0          0  \n",
      "\n",
      "[1000 rows x 28034 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paths to the folders\n",
    "spam_path = 'SpamCorpus/spam'\n",
    "easy_ham_path = 'SpamCorpus/easy_ham'\n",
    "hard_ham_path = 'SpamCorpus/hard_ham'\n",
    "\n",
    "# Reading each folder\n",
    "hard_spam = read_folder(hard_ham_path)\n",
    "easy_ham = read_folder(easy_ham_path)\n",
    "hard_ham = read_folder(hard_ham_path)\n",
    "\n",
    "# Optionally, add a label column\n",
    "hard_spam['label'] = 'hard_spam'\n",
    "easy_ham['label'] = 'easy_ham'\n",
    "hard_ham['label'] = 'ham'\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "corpus = pd.concat([hard_spam, easy_ham, hard_ham])\n",
    "\n",
    "# Apply the parse_email function to the 'email_content' column of the first 10 rows\n",
    "parsed_rows = corpus.iloc[:1000].apply(lambda row: parse_email(row['email_content'], row['label']), axis=1)\n",
    "\n",
    "# Concatenate the results\n",
    "concatenated_df = pd.concat(parsed_rows.tolist())\n",
    "\n",
    "# Vectorize the preprocessed text\n",
    "vectorizer = CountVectorizer(analyzer='word', binary=True)\n",
    "\n",
    "X = vectorizer.fit_transform(concatenated_df['Content'])\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "binary_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Optionally, you can concatenate this binary_df with the original DataFrame\n",
    "final_df = pd.concat([concatenated_df.reset_index(drop=True), binary_df], axis=1)\n",
    "\n",
    "print(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
